{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ce68a5-ef8e-4637-86a8-e04b21d0cea7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"videos/cr7&messi.mp4\"\n",
      "[ERROR:0@25.452] global /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/persistence.cpp (505) open Can't open file: 'haarCasade.xml' in read mode\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sx/7xynsy_s3kj3rnk_ggmpyynm0000gp/T/ipykernel_70006/3547304947.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m#gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "cap = cv2.VideoCapture(\"videos/cr7&messi.mp4\")\n",
    "Cascade = cv2.CascadeClassifier(\"haarCasade.xml\")\n",
    "while(True):\n",
    "            ret, frame = cap.read()\n",
    "            #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow('frame',frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "                break\n",
    "                \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69038191-a870-4f0b-b896-a830c1b70fd0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3445544085.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/sx/7xynsy_s3kj3rnk_ggmpyynm0000gp/T/ipykernel_43180/3445544085.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2. VideoCapture(\"videos/cr7&messi.mp4\")\n",
    "fourco = cv2.VideoWriter_fourcc(* 'XVID')\n",
    "out = cv2.VideoWriter ('videos/cr7&messi.mp4', fourco, 20.0, (640,480))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2. cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame', frame) \n",
    "    cv2.imshow('gray', gray)\n",
    "    if cv2.waitKey(1) & OxFF == ord('q'):\n",
    "        bгеак\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ffb3b3-585d-419c-97c8-78bf761ba531",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (65.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: packaging in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/brian/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f41c2ec-ab03-4c4a-a2c3-dce852ec3ed9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imageai.Detection import VideoObjectDetection\n",
    "\n",
    "vid_obj_detect = VideoObjectDetection()\n",
    "vid_obj_detect.setModelTypeAsYOLOv3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81a8421-9868-468a-8e46-f2569d809e0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"Desktop/fcpy/videos/cr7&messi.mp4\"\n",
      "[ERROR:0@202.272] global /Users/runner/work/opencv-python/opencv-python/opencv/modules/videoio/src/cap.cpp (597) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): C:/Datasets/output_video.avi in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vid_obj_detect.setModelPath(r\"C:/Datasets/yolo.h5\")\n",
    "detected_vid_obj = vid_obj_detect.detectObjectsFromVideo(\n",
    "    input_file_path =  r\"Desktop/fcpy/videos/cr7&messi.mp4\",\n",
    "    output_file_path = r\"C:/Datasets/output_video\",\n",
    "    frames_per_second=15,\n",
    "    log_progress=True,\n",
    "    return_detected_frame = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb2d1c-cb30-48ce-b3f0-9f27550780c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# This is a demo of running face recognition on live video from your webcam. It's a little more complicated than the\n",
    "# other example, but it includes some basic performance tweaks to make things run a lot faster:\n",
    "#   1. Process each video frame at 1/4 resolution (though still display it at full resolution)\n",
    "#   2. Only detect faces in every other frame of video.\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "image_Of_messi = face_recognition.load_image_file('images/famous/messi.jpg')\n",
    "messi_face_encoding = face_recognition.face_encodings(image_Of_messi)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "image_Of_cr7 = face_recognition.load_image_file('images/famous/cr7.jpg')\n",
    "cr7_face_encoding = face_recognition.face_encodings(image_Of_cr7)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    messi_face_encoding,\n",
    "    cr7_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Messi\",\n",
    "    \"Ronaldo\"\n",
    "]\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # face box \n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (32, 215, 137), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (32, 215, 137), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff975f4-ba0e-43a6-8647-d230b6da151e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
